{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "import functools\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\"\"\"\n",
    "Dummy Data for Linear Regression\n",
    "\"\"\"\n",
    "data = [(1, 1), (2, 2), (5, 5.5), (6, 8), (9, 10)]    \n",
    "\n",
    "\"\"\"\n",
    "Plot the line using theta_values\n",
    "\"\"\"\n",
    "def plot_line(formula, x_range, order_of_regression, label=None):\n",
    "    x = np.array(x_range).tolist()  \n",
    "    y = [formula(update_features(x_i, order_of_regression, 9)) for x_i in x]\n",
    "    l, = plt.plot(x, y, label=label)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Hypothesis Function\n",
    "\"\"\"\n",
    "def h(x, theta):\n",
    "    return np.matmul(theta.T, x)[0][0]\n",
    "\n",
    "\"\"\"\n",
    "Partial Derivative w.r.t. theta_i\n",
    "\"\"\"\n",
    "def j_prime_theta(data, theta, order_of_regression, i):\n",
    "    result = 0\n",
    "    m = len(data)\n",
    "    for x, y in data :\n",
    "        x = update_features(x, order_of_regression)\n",
    "        result += (h(x, theta) - y) * x[i]\n",
    "    \n",
    "    return (1/m) * result\n",
    "\n",
    "\"\"\"\n",
    "Update features by order of the regression\n",
    "\"\"\"\n",
    "\n",
    "def update_features(x, order_of_regression, m = 9):\n",
    "    features = [1]\n",
    "    for i in range(order_of_regression):\n",
    "        features.append(math.pow(x, i+1)/ math.pow(m, i+1))\n",
    "    return np.atleast_2d(features).T\n",
    "\n",
    "\"\"\"\n",
    "Cost Function\n",
    "\"\"\"\n",
    "def j(data, theta, order_of_regression):\n",
    "    cost = 0\n",
    "    m = len(data)\n",
    "    for x, y in data:\n",
    "        x = update_features(x, order_of_regression)\n",
    "        cost += math.pow(h(x, theta) - y, 2)\n",
    "    return (1/(2*m)) * cost\n",
    "\n",
    "\"\"\"\n",
    "Simultaneous Update\n",
    "\"\"\"\n",
    "def update_theta(data, alpha, theta, order_of_regression):\n",
    "    temp = []\n",
    "    for i in range(order_of_regression+1):\n",
    "        temp.append(theta[i] - alpha * j_prime_theta(data, theta, order_of_regression, i))\n",
    "    theta = np.array(temp)\n",
    "    return theta\n",
    "    \n",
    "\"\"\"\n",
    "Gradient Descent For Multivariate Regression\n",
    "\"\"\"\n",
    "def gradient_descent(data, alpha, tolerance, theta=[], order_of_regression = 2):\n",
    "    if len(theta) == 0:\n",
    "        theta = np.atleast_2d(np.random.random(order_of_regression+1) * 100).T\n",
    "    prev_j = 10000\n",
    "    curr_j = j(data, theta, order_of_regression)\n",
    "    print(curr_j)\n",
    "    cost_history = []\n",
    "    theta_history = [] \n",
    "    counter = 0\n",
    "    while(abs(curr_j - prev_j) > tolerance):\n",
    "        try:\n",
    "            cost_history.append(curr_j)\n",
    "            theta_history.append(theta)\n",
    "            theta = update_theta(data, alpha, theta, order_of_regression)\n",
    "            prev_j = curr_j\n",
    "            curr_j = j(data, theta, order_of_regression)\n",
    "            if counter % 100 == 0:\n",
    "                print(curr_j)\n",
    "            counter += 1\n",
    "        except:\n",
    "            break\n",
    "    print(\"Stopped with Error at %.5f\" % prev_j)\n",
    "    return theta, cost_history, theta_history\n",
    "\n",
    "theta, cost_history, theta_history = gradient_descent(data, 0.01, 0.0001, order_of_regression=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regularized Version\n",
    "\"\"\"\n",
    "def reg_j_prime_theta(data, theta, l, order_of_regression, i):\n",
    "    result = 0\n",
    "    m = len(data)\n",
    "    for x, y in data :\n",
    "        x = update_features(x, order_of_regression)\n",
    "        result += (h(x, theta) - y) * x[i]\n",
    "    result += l*theta[i]\n",
    "    return (1/m) * result\n",
    "\n",
    "def reg_j(data, theta, l, order_of_regression):\n",
    "    cost = 0\n",
    "    m = len(data)\n",
    "    for x, y in data:\n",
    "        x = update_features(x, order_of_regression)\n",
    "        cost += math.pow(h(x, theta) - y, 2)\n",
    "    reg = 0\n",
    "    for j in theta:\n",
    "        reg += math.pow(j, 2)\n",
    "    reg = reg * l\n",
    "    return (1/(2*m)) * (cost + reg)\n",
    "\n",
    "def reg_update_theta(data, alpha, theta, l, order_of_regression):\n",
    "    temp = []\n",
    "    for i in range(order_of_regression+1):\n",
    "        temp.append(theta[i] - alpha * reg_j_prime_theta(data, theta, l, order_of_regression, i))\n",
    "    theta = np.array(temp)\n",
    "    return theta\n",
    "\n",
    "def reg_gradient_descent(data, alpha, l, tolerance, theta=[], order_of_regression = 2):\n",
    "    if len(theta) == 0:\n",
    "        theta = np.atleast_2d(np.random.random(order_of_regression+1) * 100).T\n",
    "    prev_j = 10000\n",
    "    curr_j = reg_j(data, theta, l, order_of_regression)\n",
    "    print(curr_j)\n",
    "    cost_history = []\n",
    "    theta_history = [] \n",
    "    counter = 0\n",
    "    while(abs(curr_j - prev_j) > tolerance):\n",
    "        try:\n",
    "            cost_history.append(curr_j)\n",
    "            theta_history.append(theta)\n",
    "            theta = reg_update_theta(data, alpha, theta, l, order_of_regression)\n",
    "            prev_j = curr_j\n",
    "            curr_j = reg_j(data, theta, l, order_of_regression)\n",
    "            if counter % 100 == 0:\n",
    "                print(curr_j)\n",
    "            counter += 1\n",
    "        except:\n",
    "            break\n",
    "    print(\"Stopped with Error at %.5f\" % prev_j)\n",
    "    return theta, cost_history, theta_history\n",
    "reg_theta, reg_cost_history, reg_theta_history = reg_gradient_descent(data, 0.01, 1, 0.0001, order_of_regression=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "f = functools.partial(h, theta=reg_theta_history[-1])\n",
    "plt.scatter([i[0] for i in data], [i[1] for i in data])\n",
    "reg = plot_line(f, (np.array(range(10,91))/10).tolist(), order_of_regression=150, label='regularized')\n",
    "f = functools.partial(h, theta=theta_history[-1])\n",
    "unreg = plot_line(f, (np.array(range(10,91))/10).tolist(), order_of_regression=150, label='not regularized')\n",
    "plt.legend([reg, unreg], ['Regularized', 'Not Regularized'])\n",
    "plt.title('Effect of Regularization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "update_features(9,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 1000)\n",
    "ax.set_ylim(0, 10000)\n",
    "b,=plt.plot(range(len(cost_history_01)), cost_history_01, label='alpha=0.01')\n",
    "c,=plt.plot(range(len(cost_history_001)), cost_history_001, label='alpha=0.001')\n",
    "d,=plt.plot(range(len(cost_history_0001)), cost_history_0001, label='alpha=0.0001')\n",
    "e,=plt.plot(range(len(cost_history_00001)), cost_history_00001 ,label='alpha=0.00001')\n",
    "plt.legend(handles=[b, c, d, e])\n",
    "plt.title(\"Effect of learning rate\")\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.set_xlim(0, 5000)\n",
    "ax.set_ylim(0, 6000)\n",
    "plt.plot(range(len(cost_history)), cost_history)\n",
    "# plt.title(\"Optimum learning rate\")\n",
    "ax.set_xlabel('epochs')\n",
    "ax.set_ylabel('cost')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "fig, ax = plt.subplots()\n",
    "x = []\n",
    "y = []\n",
    "plt.scatter([i[0] for i in data], [i[1] for i in data])\n",
    "ln, = plt.plot(x, y, 'r--', animated=True, label='h(x)')\n",
    "plt.title('Parameter Optimization with Feature scaling')\n",
    "\n",
    "def init():\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 50)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('y')\n",
    "    plt.legend(handles=[ln])\n",
    "    return ln,\n",
    "\n",
    "def update(frame):\n",
    "    theta = frame\n",
    "    x = (np.array(range(10, 91))/10).tolist()\n",
    "    f = functools.partial(h, theta=theta)\n",
    "    y = [f(update_features(x_i, 100)) for x_i in x]\n",
    "    ln.set_data(x, y)\n",
    "    return ln,\n",
    "\n",
    "def data_gen():\n",
    "    for i in theta_history[::100]:\n",
    "        yield i\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=data_gen(),\n",
    "                    init_func=init, blit=False, interval=100)\n",
    "display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "len(theta_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "fig, ax = plt.subplots()\n",
    "x = []\n",
    "y = []\n",
    "plt.scatter([i[0] for i in data], [i[1] for i in data])\n",
    "ln, = plt.plot(x, y, 'r--', animated=True)\n",
    "plt.title('Hypothesis Parameter Optimization for Linear Regression')\n",
    "\n",
    "def init():\n",
    "    ax.set_xlim(0, 10)\n",
    "    ax.set_ylim(0, 10)\n",
    "    return ln,\n",
    "\n",
    "def update(frame):\n",
    "    theta_0 = frame[0]\n",
    "    theta_1 = frame[1]\n",
    "    x = np.array(range(10))\n",
    "    f = functools.partial(h, theta_0=theta_0, theta_1=theta_1)\n",
    "    y = f(x)\n",
    "    ln.set_data(x, y)\n",
    "    return ln,\n",
    "\n",
    "def data_gen():\n",
    "    for i, j in zip(theta_0_history[::300], theta_1_history[::300]):\n",
    "        yield i, j\n",
    "\n",
    "ani = FuncAnimation(fig, update, frames=data_gen(),\n",
    "                    init_func=init, blit=False, interval=100)\n",
    "display(HTML(ani.to_html5_video()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
